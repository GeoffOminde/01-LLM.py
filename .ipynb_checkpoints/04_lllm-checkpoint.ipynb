{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e07c7b",
   "metadata": {},
   "source": [
    "# üìò RAG System with FAISS & OpenAI\n",
    "This notebook demonstrates how to build a Retrieval-Augmented Generation (RAG) system using FAISS, LangChain, and OpenAI GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d89985",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# üìö Step 1: Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîë Step 2: Setup API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìä Step 3: Load dataset\n",
    "df = pd.read_excel(\"04LLM.xlsx\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70989bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîÑ Step 4: Convert rows into LangChain Documents\n",
    "documents = [\n",
    "    Document(page_content=row[\"Content\"], metadata={\"Title\": row[\"Title\"], \"Tags\": row[\"Tags\"], \"Source\": row[\"Source\"]})\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Split into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "docs = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks: {len(docs)}\")\n",
    "docs[:2]  # preview first 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üß† Step 5: Build FAISS index with embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîç Step 6: Test retrieval\n",
    "query = \"What is RAG?\"\n",
    "results = db.similarity_search(query, k=2)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"üìÑ Title: {r.metadata['Title']}\")\n",
    "    print(f\"üîé Content: {r.page_content}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ü§ñ Step 7: RAG function\n",
    "def rag_query(query: str):\n",
    "    results = db.similarity_search(query, k=2)\n",
    "    context = \"\\n\\n\".join([f\"{r.metadata['Title']}: {r.page_content}\" for r in results])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that answers using the retrieved context.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test it\n",
    "rag_query(\"Explain LangChain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìâ Step 8: Visualize embeddings with PCA\n",
    "# Get embeddings for all chunks\n",
    "vecs = [embeddings.embed_query(doc.page_content) for doc in docs]\n",
    "\n",
    "# Reduce dimensions with PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(vecs)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(reduced[:,0], reduced[:,1], c=\"blue\", alpha=0.6)\n",
    "for i, doc in enumerate(docs):\n",
    "    plt.text(reduced[i,0]+0.02, reduced[i,1], doc.metadata[\"Title\"], fontsize=9)\n",
    "plt.title(\"üìä Embedding Visualization of Knowledge Base\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
