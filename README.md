### ğŸ“„ PDF-based Question Answering System with LangChain

A Python-based project that allows you to query PDF documents using retrieval-augmented generation (RAG) powered by LangChain, FAISS, and OpenAI GPT models.

### ğŸš€ Features

âœ… Automatically creates a sample PDF if none exists.

ğŸ“‚ Loads and parses PDF documents.

ğŸ” Splits documents into chunks for better retrieval.

ğŸ§  Generates embeddings using OpenAI for semantic search.

âš¡ Uses FAISS for fast vector search.

ğŸ¤– Supports RAG-based question answering with LangChain LLM.

ğŸ”„ Can query the document for relevant information.

ğŸ”§ Optional .env support for storing your OpenAI API key securely.

### ğŸ› ï¸ Prerequisites

Python 3.10+

pip (Python package manager)

An OpenAI API Key with sufficient quota.

### ğŸ“¦ Installation

Clone the repository

```
git clone <your-repo-url>
cd 01-LLM.py
```

## Create a virtual environment (optional but recommended)
```
python -m venv .venv
source .venv/bin/activate      # Linux / Mac
.venv\Scripts\activate         # Windows
```

### 3.Install dependencies
```
pip install -r requirements.txt

```
Example requirements.txt includes:
```
langchain
langchain-openai
langchain-community
reportlab
python-dotenv
faiss-cpu
pandas
openpyxl
```

### 5.Set your OpenAI API Key

Create a .env file in the project root:
```
OPENAI_API_KEY=sk-<your_actual_openai_key_here>
```
ğŸ“ Usage

### 1.Run the main app
```
python app.py

```
### 2.Expected output

âœ… OpenAI API Key loaded successfully!
ğŸ“‚ Found existing sample PDF.
ğŸ“‚ Loading PDF: pdfs/sample.pdf

â“ Query: What does the document say about Large Language Models?
ğŸ“– Answer: [GPT-generated answer based on PDF content]


### 3.Query custom questions

Edit app.py:
```
query = "Explain how LLMs are used in education."
answer = qa.run(query)
print(answer)
```
### âš™ï¸ Code Structure
```
01-LLM.py/
â”‚
â”œâ”€ app.py                  # Main Python script
â”œâ”€ pdfs/
â”‚   â””â”€ sample.pdf          # Auto-generated sample PDF
â”œâ”€ .env                    # Store OPENAI_API_KEY
â”œâ”€ requirements.txt        # Python dependencies
â””â”€ README.md               # Project documentation
```
### ğŸ§  How It Works

PDF Creation / Loading

Checks if sample.pdf exists.

Creates a default PDF if missing.

Document Parsing & Chunking

Loads the PDF using PyPDFLoader.

Splits content into chunks using RecursiveCharacterTextSplitter.

Embeddings & FAISS Indexing

Generates semantic embeddings for each chunk via OpenAI.

Builds a FAISS vector database for fast similarity search.

RAG-based Querying

Retrieves the top-k relevant chunks from FAISS.

Feeds the retrieved context to a GPT model for answers.

Optional Quota Fallback

If OpenAI quota is exceeded, can return mock answers.

### âš¡ Notes & Tips

OpenAI API Quota: Ensure your API key has sufficient quota to generate embeddings and run LLM queries.

Custom PDFs: You can replace sample.pdf with your own documents in pdfs/.

Chunk Size: Adjust chunk_size and chunk_overlap for better context coverage.

LangChain LLM Models: You can switch to gpt-4o-mini, gpt-3.5-turbo, or any other model supported by your API plan.

### ğŸ›¡ï¸ Security

Never commit your OpenAI API key to GitHub.

Use .env to store credentials securely.

For deployment, consider environment variables instead of .env.

### ğŸ“š References

LangChain Documentation

OpenAI API Documentation

FAISS Vector Search

ReportLab PDF Generation

### ğŸ‘©â€ğŸ’» Author
```
Your Name
Email: youremail@example.com

GitHub: github.com/yourusername
```